{"cells":[{"cell_type":"markdown","metadata":{"id":"YSbtUgtcWsHc"},"source":["## Dependency Parsing as a Preprocessing Step for Logical Reasoning"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"id":"pT7Ba6R-zFLz","executionInfo":{"status":"error","timestamp":1640185651033,"user_tz":300,"elapsed":46837,"user":{"displayName":"elbowroom","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16478181345569282121"}},"outputId":"ea30f7cf-d90d-4b4a-e04b-8111ec3ea234"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-5bfec7158b2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdrive_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/FinalProject/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install transformers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0muse_metadata_server\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_metadata_server\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m       ephemeral=ephemeral)\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server, ephemeral)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 136\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Installs HBOX for Jupyer Notebooks\n","# !jupyter labextension install @jupyter-widgets/jupyterlab-manager\n","# !jupyter nbextension enable --py widgetsnbextension\n","# drive_path = ''\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","drive_path = '/content/drive/MyDrive/FinalProject/'\n","!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_qGQfwNPzFL0","executionInfo":{"status":"aborted","timestamp":1640185651026,"user_tz":300,"elapsed":8,"user":{"displayName":"elbowroom","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16478181345569282121"}}},"outputs":[],"source":["import os\n","import gc\n","import re\n","import json\n","import torch\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from transformers import RobertaTokenizer\n","from torch.utils.data import TensorDataset, Dataset, DataLoader, RandomSampler, SequentialSampler\n","from transformers import RobertaConfig, RobertaForSequenceClassification, AdamW\n","\n","# Enable CUDA Blocking Debugging\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","CUDA_LAUNCH_BLOCKING=\"1\"\n","\n","# Print GPU Information\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","    print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","    print('and then re-execute this cell.')\n","else:\n","    print(gpu_info)"]},{"cell_type":"markdown","metadata":{"id":"GrSiTjIeXaFn"},"source":["#### Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dN0fYjnBWmx-","executionInfo":{"status":"aborted","timestamp":1640185651028,"user_tz":300,"elapsed":10,"user":{"displayName":"elbowroom","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16478181345569282121"}}},"outputs":[],"source":["def load_data(path, test):\n","    df = pd.DataFrame({'prompt': [], 'label': []})\n","    data = json.load(open(path))\n","    for i in range(len(data['context'])):\n","        # Add BERT tokens to prompt\n","        prompt = data['context'][str(i)] + data['question'][str(i)] #+ ' </s> ' + data['question'][str(i)] + ' </s> '# + data['dep_context'][str(i)] + ' </s> '\n","        for j in range(4):\n","            # Add BERT tokens to answer\n","            answer = data['answers'][str(i)][j]# + ' <d> ' + data['dep_answers'][str(i)][j] + ' <s>'\n","            \n","            # Attach 0, 1 label as array\n","            label = [1] if not test and j == data['label'][str(i)] else [0]\n","            \n","            # Append question, answer pair to dataframe\n","            df = df.append({'prompt': prompt + answer, 'label': [label]}, ignore_index=True)            \n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RMPT4GNOzFL2","executionInfo":{"status":"aborted","timestamp":1640185651028,"user_tz":300,"elapsed":10,"user":{"displayName":"elbowroom","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16478181345569282121"}}},"outputs":[],"source":["train_data = load_data(drive_path + 'reclor_data_with_dependencies/train.json', False)\n","val_data = load_data(drive_path + 'reclor_data_with_dependencies/val.json', False)\n","test_data = load_data(drive_path + 'reclor_data_with_dependencies/test.json', True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jJJXNtvyzFL2","executionInfo":{"status":"aborted","timestamp":1640185651029,"user_tz":300,"elapsed":11,"user":{"displayName":"elbowroom","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16478181345569282121"}}},"outputs":[],"source":["# Describe the token lengths of training data\n","train_data['prompt'].apply(lambda x: len(re.findall(r'\\w+', x))).describe()"]},{"cell_type":"markdown","metadata":{"id":"QewmF4FjXdMI"},"source":["#### Initialize tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6FifoAfYWmyC","executionInfo":{"status":"aborted","timestamp":1640185651029,"user_tz":300,"elapsed":10,"user":{"displayName":"elbowroom","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16478181345569282121"}}},"outputs":[],"source":["tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","tokenizer.add_special_tokens({'additional_special_tokens': ['<d>']})"]},{"cell_type":"markdown","metadata":{"id":"ST4vzaugXe3F"},"source":["#### Tokenize the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_IwKvRzrWmyD","executionInfo":{"status":"aborted","timestamp":1640185651030,"user_tz":300,"elapsed":11,"user":{"displayName":"elbowroom","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16478181345569282121"}}},"outputs":[],"source":["# Creates a dataloader (which includes an attention mask)\n","def preprocess(in_, tokenizer, max_len, batch_size, data_class='train'):\n","    encoded_input = tokenizer(in_['prompt'].values.tolist(), padding=True, max_length=max_len, truncation=True, return_tensors=\"pt\")\n","    \n","    if data_class != 'test':\n","        labels = torch.tensor(in_['label'].values.tolist())\n","    dataset_tensor = TensorDataset(encoded_input['input_ids'], encoded_input['attention_mask'], labels)\n","    sampler = SequentialSampler(dataset_tensor)\n","    #sampler = RandomSampler(dataset_tensor) if data_class == \"train\" else SequentialSampler(dataset_tensor)\n","    dataloader = DataLoader(dataset_tensor, sampler=sampler, batch_size=batch_size)\n","    return dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IO_u0WCuzFL5","executionInfo":{"status":"aborted","timestamp":1640185651031,"user_tz":300,"elapsed":12,"user":{"displayName":"elbowroom","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16478181345569282121"}}},"outputs":[],"source":["max_len = 512 # should be 1024\n","batch_size = 4\n","\n","train_dataloader = preprocess(train_data, tokenizer, max_len, batch_size)\n","val_dataloader = preprocess(val_data, tokenizer, max_len, batch_size, data_class=\"val\")\n","# test_dataloader = preprocess(test_data, tokenizer, max_len, batch_size, data_class=\"test\")"]},{"cell_type":"code","source":["# fi = iter(val_dataloader)\n","# for i in range(100):\n","#   l = next(fi)\n","#   #print(l)\n","#   #print(l.numpy().tolist()[0])\n","#   k = tokenizer.decode(l.numpy().tolist()[0])\n","#   print(k)\n","#   j = tokenizer.decode(l.numpy().tolist()[1])\n","#   print(j)\n","#   print(l)\n","# print(next(iter(val_dataloader)))\n","# print(train_data)\n","\n","# fi = iter(val_dataloader)\n","# for i in range(10):\n","#   l = next(fi)\n","#   print(l)\n","#   print(tokenizer.decode(l[0]))\n","#   print(tokenizer.decode(l[1]))\n","\n","\n","for step, batch in enumerate(val_dataloader):\n","  labels = batch[0]\n","  print(tokenizer.decode(labels.numpy().tolist()[0]))\n","  print(tokenizer.decode(labels.numpy().tolist()[1]))"],"metadata":{"id":"CIr30vi5GXW4","executionInfo":{"status":"aborted","timestamp":1640185651031,"user_tz":300,"elapsed":12,"user":{"displayName":"elbowroom","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16478181345569282121"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BdmnMX7OXhRJ"},"source":["#### Train and Evaluate RoBERTa"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t-Uf7cPZWmyE","executionInfo":{"status":"aborted","timestamp":1640185651032,"user_tz":300,"elapsed":13,"user":{"displayName":"elbowroom","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16478181345569282121"}}},"outputs":[],"source":["def ClearTorch():\n","    torch.no_grad()\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","def Eval(model, dataloader):\n","    ClearTorch()\n","    model.eval()\n","    predictions, true_labels = [], []\n","    for step, batch in enumerate(tqdm(dataloader)):\n","        # Call model on batch\n","        input_ids, attention_mask, labels = batch[0].cuda(), batch[1].cuda(), batch[2].cuda()\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        \n","        # Convert output logit to predictions using softmax\n","        #print(labels)\n","\n","        predictions.append(torch.nn.functional.softmax(outputs.logits).argmax(0)[1].cpu().numpy().tolist())\n","        true_labels.append(labels.argmax(0).cpu().numpy().tolist()[0][0])\n","      \n","        ClearTorch()\n","\n","    return float(sum([predictions[i] == true_labels[i] for i in range(len(predictions)) ])) / float(len(predictions))\n","\n","def Train(model, train_data, lr, n_epoch):\n","    ClearTorch()\n","    optimizer = AdamW(model.parameters(), lr=lr)\n","\n","    for epoch in range(n_epoch):\n","        print(f\"Epoch {epoch}\")\n","        model.train()\n","        nb_tr_examples, nb_tr_steps, tr_loss = 0, 0, 0\n","\n","        for step, batch in enumerate(tqdm(train_data)):\n","            # RoBERTa fine-tuning\n","            input_ids, attention_mask, labels = batch[0].cuda(), batch[1].cuda(), batch[2].cuda()\n","            \n","            optimizer.zero_grad()\n","            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","            outputs.loss.backward()\n","            optimizer.step()\n","            \n","            ClearTorch()\n","            \n","            tr_loss += float(outputs.loss)\n","            nb_tr_steps += 1\n","            \n","        print(f\"Train loss on epoch {epoch}: {tr_loss / nb_tr_steps}\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LtqGmktQzFL6","executionInfo":{"status":"aborted","timestamp":1640185651032,"user_tz":300,"elapsed":12,"user":{"displayName":"elbowroom","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16478181345569282121"}}},"outputs":[],"source":["ClearTorch()\n","\n","config = RobertaConfig.from_pretrained('roberta-base')\n","# config.max_position_embeddings = max_len\n","model = RobertaForSequenceClassification.from_pretrained('roberta-base', config=config)\n","model.resize_token_embeddings(len(tokenizer))\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","if torch.cuda.device_count() > 1:\n","    model.to(device)\n","    model = torch.nn.DataParallel(model)\n","else:\n","    model.cuda()\n","    \n","learning_rate = 2e-5\n","num_epoch = 1\n","\n","Train(model, train_dataloader, learning_rate, num_epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j0WW3gYszFL6","executionInfo":{"status":"aborted","timestamp":1640185651032,"user_tz":300,"elapsed":13,"user":{"displayName":"elbowroom","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16478181345569282121"}}},"outputs":[],"source":["val_dataloader = preprocess(val_data, tokenizer, max_len, batch_size)#, data_class=\"val\")\n","print(f\"Accuracy: {Eval(model, val_dataloader)}\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Roberta_New_No_Dependency.ipynb","provenance":[{"file_id":"11k2cMaY52qPZvVHfgrRojO3dmJBYh5jp","timestamp":1639535955559}]},"kernelspec":{"display_name":"Python 3 Root Install","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"nbformat":4,"nbformat_minor":0}